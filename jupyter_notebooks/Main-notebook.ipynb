{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# **Heritige housing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to help maximize the sale prices of four inherited properties in Ames, Iowa by analyzing house features and building a machine learning model to predict house sale prices.\n",
    "We will explore several hypotheses and validate them through data analysis and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eLEkw5O0ECa"
   },
   "source": [
    "## Objectives:\n",
    "\n",
    "* The objective of this notebook is to **fetch, clean, and analyze housing data** to predict house sale prices using machine learning models. This includes:\n",
    "  * Performing **Exploratory Data Analysis (EDA)** to understand the data.\n",
    "  * Building a **predictive model** (such as a Random Forest) to predict sale prices.\n",
    "  * **Tuning the model** for accuracy and optimizing its performance.\n",
    "  * **Evaluating the model** using performance metrics such as RMSE, MAE, and R².\n",
    "\n",
    "## Inputs:\n",
    "\n",
    "* **Dataset**: The input data is from the **Ames Housing Dataset**, provided as a CSV file (`train.csv`). The dataset includes various features such as:\n",
    "  * Total square footage, year built, neighborhood, garage area, sale price, etc.\n",
    "  * Missing values or outliers may need to be handled during preprocessing.\n",
    "  \n",
    "* **Libraries**: The following Python libraries are used:\n",
    "  * **pandas** for data manipulation.\n",
    "  * **numpy** for numerical operations.\n",
    "  * **scikit-learn** for machine learning (including model training and evaluation).\n",
    "  * **matplotlib** and **seaborn** for data visualization.\n",
    "\n",
    "## Outputs:\n",
    "\n",
    "* **Exploratory Data Analysis (EDA) visualizations**: \n",
    "  * Visualizations to explore the relationship between various features and the target variable (`SalePrice`).\n",
    "  \n",
    "* **Trained Machine Learning Model**: \n",
    "  * A **Random Forest** model trained on the cleaned data, used for predicting housing prices.\n",
    "  \n",
    "* **Performance Metrics**: \n",
    "  * **Model evaluation** metrics such as **Root Mean Squared Error (RMSE)**, **Mean Absolute Error (MAE)**, and **R²** to measure the model's performance.\n",
    "\n",
    "* **Artifacts**:\n",
    "  * The **best-tuned Random Forest model** based on hyperparameter optimization.\n",
    "  * A **model performance report**, including graphs such as **Predicted vs. Actual** plot and **Residual Plot** to visualize how well the model predicts housing prices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mavJ8DibrcQ"
   },
   "source": [
    "# Section 1 imports and loading files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is just to simply load all imports and files needed in order to rurn the rest of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'streamlit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstreamlit\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mst\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Path to the CSV file inside the assets folder\n",
    "file_path = '../assets/AmesHousing.csv'\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure no leading or trailing spaces in column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Check the structure of the DataFrame\n",
    "print(\"Initial DataFrame preview:\\n\", df.head())\n",
    "print(\"Initial DataFrame columns:\", df.columns)\n",
    "\n",
    "# Reshape the DataFrame: Pivot the variable names into columns\n",
    "# Assuming the DataFrame has 'Variable' and 'Value' columns\n",
    "df_pivot = df.pivot(index=None, columns='Variable', values='Units')\n",
    "\n",
    "# Reset index if needed\n",
    "df_pivot.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the reshaped DataFrame for verification\n",
    "print(\"Reshaped DataFrame preview:\\n\", df_pivot.head())\n",
    "print(\"Columns after pivoting:\", df_pivot.columns)\n",
    "\n",
    "# Fill missing values with the median\n",
    "df_pivot.fillna(df_pivot.median(), inplace=True)\n",
    "\n",
    "# Convert categorical features to numeric\n",
    "# If 'OverallQual' or other categorical columns have not been converted, do so\n",
    "if 'OverallQual' in df_pivot.columns and df_pivot['OverallQual'].dtype == 'object':\n",
    "    print(\"Unique values in OverallQual before encoding:\", df_pivot['OverallQual'].unique())\n",
    "    le = LabelEncoder()\n",
    "    df_pivot['OverallQual'] = le.fit_transform(df_pivot['OverallQual'])\n",
    "\n",
    "# Check the YearBuilt column for issues\n",
    "if 'YearBuilt' in df_pivot.columns:\n",
    "    print(\"Unique values in YearBuilt before cleaning:\", df_pivot['YearBuilt'].unique())\n",
    "    # Clean the YearBuilt column\n",
    "    df_pivot['YearBuilt'] = pd.to_numeric(df_pivot['YearBuilt'].str.split(' - ').str[0], errors='coerce')\n",
    "    print(\"Unique values in YearBuilt after cleaning:\", df_pivot['YearBuilt'].unique())\n",
    "\n",
    "# Add new feature for total square footage if the relevant columns exist\n",
    "required_columns = ['1stFlrSF', '2ndFlrSF', 'TotalBsmtSF']\n",
    "if all(col in df_pivot.columns for col in required_columns):\n",
    "    df_pivot['TotalSF'] = df_pivot['1stFlrSF'] + df_pivot['2ndFlrSF'] + df_pivot['TotalBsmtSF']\n",
    "else:\n",
    "    print(\"One or more required columns are missing for TotalSF calculation.\")\n",
    "\n",
    "# Specify features and target variable\n",
    "X = df_pivot[['TotalSF', 'OverallQual', 'GarageArea', 'YearBuilt']]\n",
    "y = df_pivot['SalePrice']\n",
    "\n",
    "# Check the shapes of X and y before proceeding\n",
    "print(\"Shape of X before NaN handling:\", X.shape)\n",
    "print(\"Shape of y before NaN handling:\", y.shape)\n",
    "\n",
    "# Check for NaN values in features and target variable\n",
    "print(\"NaN values in X:\", X.isnull().sum())\n",
    "print(\"NaN values in y:\", y.isnull().sum())\n",
    "\n",
    "# Handle NaN values: Option 1: Drop rows with NaN values\n",
    "X = X.dropna()\n",
    "y = y[X.index]  # Align y with X after dropping\n",
    "\n",
    "# Alternatively, you can fill NaN values instead of dropping\n",
    "# X.fillna(X.median(), inplace=True)\n",
    "\n",
    "# Check the shape after dropping NaNs\n",
    "print(\"Shape of X after NaN handling:\", X.shape)\n",
    "print(\"Shape of y after NaN handling:\", y.shape)\n",
    "\n",
    "# Check if there are any samples left to split\n",
    "if X.shape[0] == 0 or y.shape[0] == 0:\n",
    "    print(\"No samples left for training and testing. Please check your data handling steps.\")\n",
    "else:\n",
    "    # Split into training and testing datasets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train the Random Forest model\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Title of the dashboard\n",
    "    st.title(\"Heritage Housing Price Prediction Dashboard\")\n",
    "\n",
    "    # Write introduction text\n",
    "    st.write(\"This dashboard helps predict house prices in Ames, Iowa using Exploratory Data Analysis and machine learning models.\")\n",
    "\n",
    "    # Display the first few rows of the dataset for reference\n",
    "    st.write(\"### Ames Housing Dataset Preview:\")\n",
    "    st.dataframe(df_pivot.head())\n",
    "\n",
    "    # Display the shape of the dataset (rows and columns)\n",
    "    st.write(f\"Number of Rows: {df_pivot.shape[0]}, Number of Columns: {df_pivot.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY3l0-AxO93d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFQo3ycuO-v6"
   },
   "source": [
    "# Section 2 EDA Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is about the Analysis and plotting of the dataset given to me when i first forked the template at the start of this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.subheader('Exploratory Data Analysis')\n",
    "\n",
    "# Display the shape of the DataFrame\n",
    "st.write(f\"DataFrame Shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "st.write(\"Missing Values in Each Column:\")\n",
    "st.write(missing_values)\n",
    "\n",
    "# Check if the DataFrame is empty\n",
    "if df.empty:\n",
    "    st.write(\"The DataFrame is empty. Please check the data loading process.\")\n",
    "else:\n",
    "    # Try to select only numeric columns for correlation\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "    # Check if there are any numeric columns to calculate the correlation\n",
    "    if numeric_df.empty:\n",
    "        st.write(\"No numeric columns available to calculate correlation.\")\n",
    "    else:\n",
    "        # Correlation Heatmap\n",
    "        st.write(\"### Correlation Heatmap\")\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', fmt='.2f', ax=ax)\n",
    "        st.pyplot(fig)\n",
    "\n",
    "        # Ensure 'TotalSF' and 'SalePrice' exist in DataFrame\n",
    "        if 'TotalSF' in df.columns and 'SalePrice' in df.columns:\n",
    "            # Scatter plot for Total Square Footage vs Sale Price\n",
    "            st.write(\"### Total Square Footage vs Sale Price\")\n",
    "            fig = px.scatter(df, x='TotalSF', y='SalePrice', opacity=0.5, title='Total Square Footage vs Sale Price')\n",
    "            st.plotly_chart(fig)\n",
    "\n",
    "            # Box plot for Neighborhood vs Sale Price\n",
    "            if 'Neighborhood' in df.columns:\n",
    "                st.write(\"### Neighborhood vs Sale Price\")\n",
    "                fig = px.box(df, x='Neighborhood', y='SalePrice', title='Neighborhood vs Sale Price')\n",
    "                st.plotly_chart(fig)\n",
    "            else:\n",
    "                st.write(\"Column 'Neighborhood' not found in the dataset.\")\n",
    "\n",
    "            # Scatter plot for Overall Quality vs Sale Price\n",
    "            if 'OverallQual' in df.columns:\n",
    "                st.write(\"### Overall Quality vs Sale Price\")\n",
    "                fig = px.scatter(df, x='OverallQual', y='SalePrice', opacity=0.5, title='Overall Quality vs Sale Price')\n",
    "                st.plotly_chart(fig)\n",
    "            else:\n",
    "                st.write(\"Column 'OverallQual' not found in the dataset.\")\n",
    "\n",
    "            # Scatter plot for Year Built vs Sale Price\n",
    "            if 'YearBuilt' in df.columns:\n",
    "                st.write(\"### Year Built vs Sale Price\")\n",
    "                fig = px.scatter(df, x='YearBuilt', y='SalePrice', opacity=0.5, title='Year Built vs Sale Price')\n",
    "                st.plotly_chart(fig)\n",
    "            else:\n",
    "                st.write(\"Column 'YearBuilt' not found in the dataset.\")\n",
    "\n",
    "            # Scatter plot for Garage Area vs Sale Price\n",
    "            if 'GarageArea' in df.columns:\n",
    "                st.write(\"### Garage Area vs Sale Price\")\n",
    "                fig = px.scatter(df, x='GarageArea', y='SalePrice', opacity=0.5, title='Garage Area vs Sale Price')\n",
    "                st.plotly_chart(fig)\n",
    "            else:\n",
    "                st.write(\"Column 'GarageArea' not found in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Section 3 Machine learning model development**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is all about the predictions and evaluations from different models in the dataset given such as:\n",
    "- Linear regression model\n",
    "- Random Forest Model\n",
    "    - Hyperperameter tuning for the RFM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if 'TotalSF' exists, and if not, notify the user\n",
    "if 'TotalSF' not in df.columns:\n",
    "    st.error(\"The column 'TotalSF' is not found in the dataset. Please check the column names.\")\n",
    "else:\n",
    "    # Sidebar for user input\n",
    "    st.sidebar.header(\"Input Features\")\n",
    "    total_sf = st.sidebar.slider('Total Square Footage', int(df['TotalSF'].min()), int(df['TotalSF'].max()), int(df['TotalSF'].mean()))\n",
    "    overall_qual = st.sidebar.slider('Overall Quality', int(df['OverallQual'].min()), int(df['OverallQual'].max()), int(df['OverallQual'].mean()))\n",
    "    garage_area = st.sidebar.slider('Garage Area', int(df['GarageArea'].min()), int(df['GarageArea'].max()), int(df['GarageArea'].mean()))\n",
    "    year_built = st.sidebar.slider('Year Built', int(df['YearBuilt'].min()), int(df['YearBuilt'].max()), int(df['YearBuilt'].mean()))\n",
    "\n",
    "    # Predict house price based on input\n",
    "    if st.sidebar.button(\"Predict Sale Price\"):\n",
    "        try:\n",
    "            price = predict_price(total_sf, overall_qual, garage_area, year_built)\n",
    "            st.write(f\"### Predicted Sale Price: ${price:,.2f}\")\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error in prediction: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Section 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation Section\n",
    "st.subheader(\"Model Evaluation\")\n",
    "st.write(\"### Residuals Plot\")\n",
    "\n",
    "# Generate predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Create the residuals plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.scatter(y_test, y_test - y_pred_rf, alpha=0.5, edgecolor='b', s=50)\n",
    "ax.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "ax.set_title('Residuals Plot', fontsize=16)\n",
    "ax.set_xlabel('Actual Sale Price', fontsize=14)\n",
    "ax.set_ylabel('Residuals', fontsize=14)\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "# Display the plot in Streamlit\n",
    "st.pyplot(fig)\n",
    "\n",
    "# Display R² and RMSE for the model\n",
    "r2 = r2_score(y_test, y_pred_rf)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "\n",
    "st.write(f\"### Random Forest R²: {r2:.4f}\")\n",
    "st.write(f\"### Random Forest RMSE: {rmse:.2f}\")\n",
    "\n",
    "# Provide additional interpretation\n",
    "st.write(\"\"\"\n",
    "**Interpretation of the Residuals Plot**:\n",
    "- The residuals should ideally be randomly scattered around zero without any clear pattern.\n",
    "- If the residuals show a pattern (e.g., a curve), it might indicate that the model is not capturing some information in the data.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conclusion**\n",
    "From the analysis, we found that larger homes, higher quality, and newer homes fetch higher sale prices. Features such as location (neighborhood) and garage space also impact prices significantly. The best-tuned Random Forest model provided accurate predictions, and feature importance analysis showed that house size and overall quality are key drivers of sale price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Credits and Acknowledgements\n",
    "- Dataset from Ames Housing Dataset.\n",
    "- Inspiration from Machine Learning and Data Analysis walkthrough projects\n",
    "- My mentor precious ijege for his guidance in this project\n",
    "- My fellow peers such as Beth Cottel for checking in with me when times were tuff during this development (and for keeping me smiling aswell as motivated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations and Next steps\n",
    "* One limitation of the model is that we focused on a subset of features; other factors such as market conditions or interior characteristics might also impact house prices."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
